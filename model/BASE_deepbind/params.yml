# general parameters
batch_size : 32
epochs     : 1

# train/validation/test data.
train_dir : ../../data/train_data
val_dir   : ../../data/train_data
test_dir  : ../../data/test_data
x_data:
  input_sequence : sequence.npy
y_data:
  embedding : gene_coexp.npy

# optimizer
optimizer  : adam
optimizer_kwargs:
  lr      : 0.001
  beta_1  : 0.9
  beta_2  : 0.999
  epsilon : 0.0000001
  amsgrad : False

# loss
loss_layers:
  - embedding
loss_embedding : tripletloss
loss_embedding_kwargs:
  margin      : 0.5
  squared     : False
  strategy    : batch_all
  label_index : 0
  distance    : euclid

# metrics
metric_layers:
  - embedding
metric_embedding  : nearest_label_accuracy

#=========
# Model
#=========

model : deeperbind

latent_space_dim    : 128
latent_space_dim_gf : 1.4928245388 # growth factor applied to determine size of next middle layer.

# convolution parameters
num_conv_layers   : 6
conv_dim_depth    : 8
conv_dim_width    : 9
conv_depth_gf     : 1.15875438383
conv_width_gf     : 1.1758149644
conv_dropout_rate : 0.0
conv_activation   : tanh
is_batchnorm_conv : true

# lstm parameters
num_lstm_layers   : 2
lstm_activation   : tanh
lstm_dropout_rate : 0.0
is_batchnorm_lstm : true

# dense parameters
num_dense_layers    : 2
dense_activation    : tanh
dense_dropout_rate  : 0.25
is_batchnorm_dense  : true
